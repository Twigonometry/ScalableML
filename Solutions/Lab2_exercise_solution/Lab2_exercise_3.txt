Conda uses environments to load different sets of Python packages
type conda env list to see the environments availible.
21/02/18 06:32:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/02/18 06:32:41 INFO SparkContext: Running Spark version 3.0.1
21/02/18 06:32:41 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
21/02/18 06:32:41 INFO ResourceUtils: ==============================================================
21/02/18 06:32:41 INFO ResourceUtils: Resources for spark.driver:

21/02/18 06:32:41 INFO ResourceUtils: ==============================================================
21/02/18 06:32:41 INFO SparkContext: Submitted application: Lab 2 Exercise
21/02/18 06:32:41 INFO SecurityManager: Changing view acls to: acq18mc
21/02/18 06:32:41 INFO SecurityManager: Changing modify acls to: acq18mc
21/02/18 06:32:41 INFO SecurityManager: Changing view acls groups to: 
21/02/18 06:32:41 INFO SecurityManager: Changing modify acls groups to: 
21/02/18 06:32:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(acq18mc); groups with view permissions: Set(); users  with modify permissions: Set(acq18mc); groups with modify permissions: Set()
21/02/18 06:32:41 INFO Utils: Successfully started service 'sparkDriver' on port 42195.
21/02/18 06:32:41 INFO SparkEnv: Registering MapOutputTracker
21/02/18 06:32:41 INFO SparkEnv: Registering BlockManagerMaster
21/02/18 06:32:41 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/02/18 06:32:41 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/02/18 06:32:41 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/02/18 06:32:41 INFO DiskBlockManager: Created local directory at /mnt/fastdata/acq18mc/blockmgr-e0e54038-efdd-47f5-84ee-65092fbc7a70
21/02/18 06:32:41 INFO MemoryStore: MemoryStore started with capacity 408.9 MiB
21/02/18 06:32:41 INFO SparkEnv: Registering OutputCommitCoordinator
21/02/18 06:32:41 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/02/18 06:32:42 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://sharc-node176.shef.ac.uk:4040
21/02/18 06:32:42 INFO Executor: Starting executor ID driver on host sharc-node176.shef.ac.uk
21/02/18 06:32:42 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36425.
21/02/18 06:32:42 INFO NettyBlockTransferService: Server created on sharc-node176.shef.ac.uk:36425
21/02/18 06:32:42 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/02/18 06:32:42 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, sharc-node176.shef.ac.uk, 36425, None)
21/02/18 06:32:42 INFO BlockManagerMasterEndpoint: Registering block manager sharc-node176.shef.ac.uk:36425 with 408.9 MiB RAM, BlockManagerId(driver, sharc-node176.shef.ac.uk, 36425, None)
21/02/18 06:32:42 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, sharc-node176.shef.ac.uk, 36425, None)
21/02/18 06:32:42 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, sharc-node176.shef.ac.uk, 36425, None)
21/02/18 06:32:42 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/acq18mc/com6012-2021/ScalableML/HPC/spark-warehouse').
21/02/18 06:32:42 INFO SharedState: Warehouse path is 'file:/home/acq18mc/com6012-2021/ScalableML/HPC/spark-warehouse'.
21/02/18 06:32:53 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
21/02/18 06:32:53 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
+---+---------------+------------------+--------------------+--------------------+--------------------+----------+
| id|           text|             words|            features|       rawPrediction|         probability|prediction|
+---+---------------+------------------+--------------------+--------------------+--------------------+----------+
|  4|   spark hadoop|   [spark, hadoop]|(262144,[173558,1...|[0.70507805796438...|[0.66931267982610...|       0.0|
|  5|    spark a b c|  [spark, a, b, c]|(262144,[74920,10...|[-5.2944383865315...|[0.00499436369321...|       1.0|
|  6|mapreduce spark|[mapreduce, spark]|(262144,[132966,1...|[0.70507805796438...|[0.66931267982610...|       0.0|
+---+---------------+------------------+--------------------+--------------------+--------------------+----------+

(4, spark hadoop) --> prob=[0.669312679826,0.330687320174], prediction=0.000000
(5, spark a b c) --> prob=[0.00499436369322,0.995005636307], prediction=1.000000
(6, mapreduce spark) --> prob=[0.669312679826,0.330687320174], prediction=0.000000
